import theano
import theano.tensor as T
import lasagne as nn
from lasagne.layers import dnn
import nn_eyes
import data
import buffering
import tmp_dnn
import numpy as np

validate_every = 20
save_every = 20

num_chunks = 100
chunk_size = 6400
batch_size = 64
im_height = 96
im_width = 96
image_size = (96, 96)

# Set momentum hyper parameter to 0.9
momentum = 0.9

# Specify learning rate decay during training
learning_rate_schedule = {
    0: 0.003,
    50: 0.001,
    100: 0.0003,
}

augmentation_params = {
    #'zoom_range': (1 / 1.1, 1.1),
    #'rotation_range': (0, 360),
    #'color_pertube': True
}

# Conv2DLayer = nn.layers.Conv2DLayer
# MaxPool2DLayer = nn.layers.MaxPool2DLayer

Conv2DLayer = dnn.Conv2DDNNLayer
MaxPool2DLayer = tmp_dnn.MaxPool2DDNNLayer

#    l1a = Conv2DLayer(l0c, num_filters=32, filter_size=(3, 3), border_mode="same", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)
#    l1b = Conv2DLayer(l1a, num_filters=16, filter_size=(3, 3), border_mode="same", W=nn_plankton.Conv2DOrthogonal(1.0), b=nn.init.Constant(0.1), nonlinearity=nn_plankton.leaky_relu)
#    l1 = MaxPool2DLayer(l1b, ds=(3, 3), strides=(2, 2))
#    l1r = dihedral.CyclicConvRollLayer(l1)


def build_model():
    l_in = nn.layers.InputLayer((batch_size, 3, im_height, im_width))

    l1_conv = Conv2DLayer(l_in, num_filters=16, filter_size=(3, 3), border_mode='same', W=nn.init.Orthogonal('relu'))
    l1_pool = MaxPool2DLayer(l1_conv, ds=(2, 2), strides=(2, 2))

    l2_conv = Conv2DLayer(l1_pool, num_filters=32, filter_size=(3, 3), border_mode='same', W=nn.init.Orthogonal('relu'))
    l2_pool = MaxPool2DLayer(l2_conv, ds=(2, 2), strides=(2, 2))

    l3_conv = Conv2DLayer(l2_pool, num_filters=64, filter_size=(3, 3), border_mode='same', W=nn.init.Orthogonal('relu'))
    l3_pool = MaxPool2DLayer(l3_conv, ds=(2, 2), strides=(2, 2))

    l4 = nn.layers.DenseLayer(nn.layers.dropout(l3_pool, p=0.5), num_units=128, W=nn.init.Orthogonal('relu'))

    l5 = nn.layers.DenseLayer(nn.layers.dropout(l4, p=0.5), num_units=128, W=nn.init.Orthogonal('relu'))

    l_out = nn.layers.DenseLayer(nn.layers.dropout(l5, p=0.5), num_units=1, nonlinearity=None, W=nn.init.Orthogonal(), b=nn.init.Constant(2))

    return l_in, l_out


def minus_kappa(y, t):
    return -nn_eyes.continuous_weighted_kappa(y[:, 0], t[:, 0])  # turn them back into 1D vectors


def build_objective(l_in, l_out):
    return nn.objectives.Objective(l_out, loss_function=nn.objectives.mse)


def create_train_gen():
    # Generator function that yields a new image and corresponding label when it's called
    image_gen = data.gen_images(data.paths_my_train, data.labels_my_train, shuffle=True, repeat=True)

    # Generator function that takes the image generated by image_gen and transform according to the parameters
    # set in "augmentation_params" or according to the default parameters specified inside the functions.
    def augmented_image_gen():
        for image, label in image_gen:
           # yield data.augment_image(image, image_size, augmentation_params), label
            yield image, label
    # Generator that generates chunk of data where the images have transformed by the function augmented_image_gen
    chunks_gen = data.gen_chunks(augmented_image_gen(), image_size=image_size, chunk_size=chunk_size, labels=True)
    return buffering.buffered_gen_threaded(chunks_gen)
